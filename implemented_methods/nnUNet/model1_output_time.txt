

Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

using model stored in  /homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1
This model expects 2 input modalities for each image
Found 1 unique case ids, here are some examples: ['HNC02_000']
If they don't look right, make sure to double check your filenames. They must end with _0000.nii.gz etc
number of cases: 1
number of cases that still need to be predicted: 1
emptying cuda cache
loading parameters for folds, None
folds is None so we will automatically look for output folders (not using 'all'!)
found the following folds:  ['/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4']
using the following model files:  ['/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_final_checkpoint.model', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1/model_final_checkpoint.model', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2/model_final_checkpoint.model', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3/model_final_checkpoint.model', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4/model_final_checkpoint.model']
starting preprocessing generator
starting prediction...
preprocessing /homes/kovacs/project_data/hnc-auto-contouring/hnc_rigs_all/data_nifty/t_r196/predictions/nnunet/labels_nn_unet_m1/HNC02_000.nii.gz
using preprocessor GenericPreprocessor
before crop: (2, 175, 512, 512) after crop: (2, 175, 512, 512) spacing: [2.        0.9765625 0.9765625] 

no separate z, order 3
no separate z, order 1
before: {'spacing': array([2.       , 0.9765625, 0.9765625]), 'spacing_transposed': array([2.       , 0.9765625, 0.9765625]), 'data.shape (data is transposed)': (2, 175, 512, 512)} 
after:  {'spacing': array([3.32215628, 1.67129929, 1.67129929]), 'data.shape (data is resampled)': (2, 105, 299, 299)} 

(2, 105, 299, 299)
This worker has ended successfully, no errors to report
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
predicting /homes/kovacs/project_data/hnc-auto-contouring/hnc_rigs_all/data_nifty/t_r196/predictions/nnunet/labels_nn_unet_m1/HNC02_000.nii.gz
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (2, 105, 299, 299)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 41], [0, 54, 107], [0, 54, 107]]
number of tiles: 27
computing Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (2, 105, 299, 299)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 41], [0, 54, 107], [0, 54, 107]]
number of tiles: 27
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (2, 105, 299, 299)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 41], [0, 54, 107], [0, 54, 107]]
number of tiles: 27
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (2, 105, 299, 299)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 41], [0, 54, 107], [0, 54, 107]]
number of tiles: 27
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (2, 105, 299, 299)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 41], [0, 54, 107], [0, 54, 107]]
number of tiles: 27
using precomputed Gaussian
prediction done
inference done. Now waiting for the segmentation export to finish...
postprocessing...

real	1m24.362s
user	1m5.919s
sys	0m11.353s

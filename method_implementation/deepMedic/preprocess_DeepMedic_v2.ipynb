{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data for DeepMedic\n",
    "\n",
    "### Loading packages needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MEDIcaTe.nii_resampling import *\n",
    "from MEDIcaTe.file_folder_ops import *\n",
    "from MEDIcaTe.utilities import *\n",
    "from MEDIcaTe.roi_generators import *\n",
    "from MEDIcaTe.visualize_labels_ct_pet import *\n",
    "from MEDIcaTe.normalize import *\n",
    "from random import sample\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create a \"raw-data-base\" explicitly for DeepMedic where all data is resampled to same size.\n",
    "\n",
    "Here we will use the medican voxel size of the entire dataset. \n",
    "Go through all images and get voxel sizes. Then get the median of this data. \n",
    "\n",
    "This script assumes that the 'path_to_data' only holds nifty files and that these are named according to the convention: \n",
    "<dataset_name>_<pt_num>_<modality_code>.nii.gz\n",
    "\n",
    "In our data these are:\n",
    "dataset_name = 'HNC01'\n",
    "pt_num = from 000 up to 835\n",
    "modality code = 0000 for CT and 0001 for PET\n",
    "\n",
    "### Find median voxel size in data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_raw_data_base/nnUNet_raw_data/Task500_HNC01/imagesTr'\n",
    "x_all = []\n",
    "y_all = []\n",
    "z_all = []\n",
    "\n",
    "# Run through all patient CT cases and get the pixel dimensions\n",
    "# Note this takes a while if you have many cases. \n",
    "# For me: approx 1,5 minutes for 836 cases.\n",
    "for i,f in enumerate(listdir(path_to_data)):\n",
    "    if f[-11:-7] == '0000':\n",
    "        x, y, z = find_pix_dim_with_orientation(join(path_to_data,f)) # \n",
    "        x_all.append(x)\n",
    "        y_all.append(y)\n",
    "        z_all.append(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected resample voxel size is (x,y,z) = (-0.9765625, 0.9765625, 2.0)\n"
     ]
    }
   ],
   "source": [
    "median_x = np.median(x_all)\n",
    "median_y = np.median(y_all)\n",
    "median_z = np.median(z_all)\n",
    "\n",
    "print(f'The selected resample voxel size is (x,y,z) = ({median_x}, {median_y}, {median_z})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the size we wish to resample to. \n",
    "We perform the resampling in the following step.\n",
    "\n",
    "### Resample the image data\n",
    "Note, that nibabel.processing.resample does not take negative numbers as input on the voxel_size parameter, so the images have to manualle flipped to (L,A,S) orientation after resampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_raw_data_base/nnUNet_raw_data/Task500_HNC01/imagesTr'\n",
    "output_path = '/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifty/d_train_raw_data_base/images'\n",
    "# hard-code numbers if above already run once.\n",
    "median_x = -0.9765625\n",
    "median_y = 0.9765625\n",
    "median_z = 2.0\n",
    "voxel_size = (median_x, median_y, median_z)\n",
    "for i,f in enumerate(listdir(path_to_data)): # go through all files on path\n",
    "    file_to_resample = join(path_to_data,f)\n",
    "    output_file = join(output_path,f)\n",
    "    if isfile(output_file):\n",
    "        pix_dims = find_pix_dim_with_orientation(output_file) # checking orientation of already resampled case\n",
    "    if not isfile(output_file): # only process files if not created aready\n",
    "        resample(join(path_to_data,f), output_path, voxel_size, verbose = True)\n",
    "    elif pix_dims != voxel_size: # reprocess if the voxel-size of existing case is not correct\n",
    "        resample(join(path_to_data,f), output_path, voxel_size, verbose = True)\n",
    "    else:\n",
    "        print(f'Apparent success on {f}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_raw_data_base/nnUNet_raw_data/Task500_HNC01/labelsTr/'\n",
    "output_path = '/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifty/d_train_raw_data_base/labels'\n",
    "median_x = -0.9765625\n",
    "median_y = 0.9765625\n",
    "median_z = 2.0\n",
    "voxel_size = (median_x, median_y, median_z)\n",
    "\n",
    "for case in listdir(input_path):\n",
    "    cur_case = join(input_path,case)\n",
    "    resample(cur_case, output_path, voxel_size, order = 0, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orientation check\n",
    "To be on the safe side, we make an extra check, if all orientations are (L,A,S). In case not, the following script prints an alarm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 alarms were produced. Looking good to proceed.\n"
     ]
    }
   ],
   "source": [
    "# Control orientation of all the resampled images\n",
    "# Outputting alarm-message every time orientation is not ('L', 'A', 'S')\n",
    "path_resampled_dat = '/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifty/d_train_raw_data_base/images'\n",
    "for i,f in enumerate(listdir(path_resampled_dat)): # go through all files on path\n",
    "    k = 0\n",
    "    cur_file = join(path_resampled_dat,f)\n",
    "    orientation = control_nii_orientation(cur_file)\n",
    "    if orientation != ('L','A','S'):\n",
    "        print(f'Alarm: {f} had orientation {orientation}.')\n",
    "        k += 1\n",
    "if k > 0:\n",
    "    print(f'{k} alarms were produced. Return to what went wrong.')\n",
    "else:\n",
    "    print(f'{k} alarms were produced. Looking good to proceed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 alarms were produced. Looking good to proceed.\n"
     ]
    }
   ],
   "source": [
    "# Do the same for the labels\n",
    "\n",
    "# Control orientation of all the resampled labels\n",
    "# Outputting alarm-message every time orientation is not ('L', 'A', 'S')\n",
    "path_resampled_dat = '/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifty/d_train_raw_data_base/labels'\n",
    "for i,f in enumerate(listdir(path_resampled_dat)): # go through all files on path\n",
    "    k = 0\n",
    "    cur_file = join(path_resampled_dat,f)\n",
    "    orientation = control_nii_orientation(cur_file)\n",
    "    if orientation != ('L','A','S'):\n",
    "        print(f'Alarm: {f} had orientation {orientation}.')\n",
    "        k += 1\n",
    "if k > 0:\n",
    "    print(f'{k} alarms were produced. Return to what went wrong.')\n",
    "else:\n",
    "    print(f'{k} alarms were produced. Looking good to proceed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate ROIs\n",
    "Before we can normalize we need some ROIs. \n",
    "These are created in agreement with Kamnitas et al.\n",
    "The ROI is based on smoothing the PET with $\\sigma = 5$ and then thresholding with all intensities $<0.2$ SUV set to air and the rest as the body. \n",
    "The normalization and sampling for DeepMedic will be based on this ROI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generetng the ROIS\n",
    "destination_path = '/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifty/d_train/rois'\n",
    "pt_images_nifty = '/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifty/d_train_raw_data_base/images/'\n",
    "#generate_rois_dm_pt(pt_image_nifty, destination_path)\n",
    "\n",
    "# go through all cases and generate the roi nifty's\n",
    "for i, nifty_image in enumerate(listdir(pt_images_nifty)):\n",
    "    cur_nifty_image = join(pt_images_nifty, nifty_image)\n",
    "    if nifty_image[-11:-7] == '0001' and nifty_image == 'HNC01_521_0001.nii.gz': # only run for PET files\n",
    "        #print(nifty_image)\n",
    "        generate_rois_dm_pt(cur_nifty_image, destination_path, clobber = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing 20 randomly sampled cases \n",
    "final_path = '/homes/kovacs/project_scripts/hnc_segmentation/MEDIcaTe/deepMedic/figures/roi_check'\n",
    "ct_path = '/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifty/d_train_raw_data_base/images/'\n",
    "pet_path = '/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifty/d_train_raw_data_base/images/'\n",
    "roi_path = '/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifty/d_train/rois/'\n",
    "\n",
    "random_20_cases = sample(listdir(ct_path),20)\n",
    "\n",
    "for case in random_20_cases:\n",
    "    case_id = case[:-12]\n",
    "    ct_fname_path = join(ct_path,f'{case_id}_0000.nii.gz')\n",
    "    pet_fname_path = join(pet_path,f'{case_id}_0001.nii.gz')\n",
    "    roi_fname_path = join(roi_path,f'{case_id}_0001_roi.nii.gz')\n",
    "    # note that this version of visualization is not optimied ant does take\n",
    "    # about 10 minutes to run for each case.\n",
    "    visualization(final_path, ct_path=ct_fname_path, \n",
    "                  pet_path=pet_fname_path, label1_path=roi_fname_path, \n",
    "                  label2_path=roi_fname_path) # , slice_range = list(range(0, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize case HNC01_437_0001.nii.gz which is failing\n",
    "final_path = '/homes/kovacs/project_scripts/hnc_segmentation/MEDIcaTe/deepMedic/figures/roi_check'\n",
    "ct_fname_path = '/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifty/d_train_raw_data_base/images/HNC01_521_0000.nii.gz'\n",
    "pet_fname_path = '/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifty/d_train_raw_data_base/images/HNC01_521_0001.nii.gz'\n",
    "roi_fname_path = '/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifty/d_train/rois/HNC01_521_0001_roi.nii.gz'\n",
    "visualization(final_path, ct_path=ct_fname_path, \n",
    "                  pet_path=pet_fname_path,\n",
    "                  label1_path=roi_fname_path,\n",
    "                  label2_path=roi_fname_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_mean_roi = 1.4963958237389199, input_std_roi = 1.9662202375742805\n"
     ]
    }
   ],
   "source": [
    "ct_fname_path = '/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifty/d_train_raw_data_base/images/HNC01_521_0000.nii.gz'\n",
    "pet_fname_path = '/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifty/d_train_raw_data_base/images/HNC01_521_0001.nii.gz'\n",
    "roi_fname_path = '/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifty/d_train/rois/HNC01_521_0001_roi.nii.gz'\n",
    "input_mean_roi, input_std_roi = get_nii_mean_std_in_roi(input_nii=pet_fname_path, input_roi=roi_fname_path)\n",
    "print(f'input_mean_roi = {input_mean_roi}, input_std_roi = {input_std_roi}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize images\n",
    "The PET and CT images are normalized to 0 mean and unit variance in accorance with DeepMedic documentation.\n",
    "\n",
    "Start by getting the normalization parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-86.70951920247971\n",
      "449.6891469125435\n",
      "1.454322559282762\n",
      "1.9064418631810773\n"
     ]
    }
   ],
   "source": [
    "# add paths to all images, rois and where \n",
    "pt_images_nifty = '/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifty/d_train_raw_data_base/images/'\n",
    "roi_path = '/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifty/d_train/rois'\n",
    "\n",
    "# case HNC01_437_0001.nii.gz is failing ??? \n",
    "\n",
    "# get mean and std for CT\n",
    "input_mean_roi_ct = []\n",
    "input_std_roi_ct = []\n",
    "for i, nifty_image in enumerate(listdir(pt_images_nifty)):\n",
    "    cur_nii_image = join(pt_images_nifty, nifty_image)\n",
    "    if nifty_image[-11:-7] == '0000': #only do anything if CT\n",
    "        cur_roi = join(roi_path, f'{basename(cur_nii_image[:-12])}_0001_roi.nii.gz')\n",
    "        input_mean_roi, input_std_roi = get_nii_mean_std_in_roi(input_nii=cur_nii_image, input_roi=cur_roi)\n",
    "        input_mean_roi_ct.append(input_mean_roi)\n",
    "        input_std_roi_ct.append(input_std_roi)\n",
    "\n",
    "\n",
    "# get mean and std for PET\n",
    "input_mean_roi_pet = []\n",
    "input_std_roi_pet = []\n",
    "for i, nifty_image in enumerate(listdir(pt_images_nifty)):\n",
    "    cur_nii_image = join(pt_images_nifty, nifty_image)\n",
    "    if nifty_image[-11:-7] == '0001': #only do anything if CT\n",
    "        cur_roi = join(roi_path, f'{basename(cur_nii_image[:-12])}_0001_roi.nii.gz')\n",
    "        input_mean_roi, input_std_roi = get_nii_mean_std_in_roi(input_nii=cur_nii_image, input_roi=cur_roi)\n",
    "        input_mean_roi_pet.append(input_mean_roi)\n",
    "        input_std_roi_pet.append(input_std_roi)\n",
    "\n",
    "# get final metrics\n",
    "ct_mean_gl = np.mean(input_mean_roi_ct)\n",
    "ct_std_gl = np.mean(input_std_roi_ct)\n",
    "pet_mean_gl = np.mean(input_mean_roi_pet)\n",
    "pet_std_gl = np.mean(input_std_roi_pet)\n",
    "\n",
    "print(ct_mean_gl)\n",
    "print(ct_std_gl)\n",
    "print(pet_mean_gl)\n",
    "print(pet_std_gl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we find the statistics:\n",
    "\n",
    "ct_mean_gl = -86.70951920247971\n",
    "\n",
    "ct_std_gl = 449.6891469125435\n",
    "\n",
    "pet_mean_gl = 1.454322559282762\n",
    "\n",
    "pet_std_gl = 1.9064418631810773"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then normalize using the obtained values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I executed w.o. errors\n"
     ]
    }
   ],
   "source": [
    "# Normalize all files\n",
    "pt_images_nifty = '/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifty/d_train_raw_data_base/images/'\n",
    "destination_path = '/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifty/d_train/images_normalized'\n",
    "\n",
    "'''\n",
    "in case not already set, use this bit (for my HNC_01 data)\n",
    "\n",
    "ct_mean_gl = -86.70951920247971\n",
    "ct_std_gl = 449.6891469125435\n",
    "pet_mean_gl = 1.454322559282762\n",
    "pet_std_gl = 1.9064418631810773\n",
    "'''\n",
    "\n",
    "for f in listdir(pt_images_nifty):\n",
    "    input_nii = join(pt_images_nifty, f)\n",
    "    if f[-11:-7] == '0000':\n",
    "        norm_0mean_1variance(input_nii, destination_path, ct_mean_gl, ct_std_gl)\n",
    "    elif f[-11:-7] == '0001':\n",
    "        norm_0mean_1variance(input_nii, destination_path, pet_mean_gl, pet_std_gl)\n",
    "\n",
    "\n",
    "print('I executed w.o. errors')\n",
    "# TODO: QA of content in /homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifty/d_train/images_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate config files\n",
    "Finally we can generate the config files necessary to run DeepMedic.\n",
    "\n",
    "Since we are training 5-fold cross-validation, need to generate config-files for each of the five folds. Eventually we will use majority voting between predictions of the 5 models in order get the final segmentation of DeepMedic.\n",
    "\n",
    "Note: For the data_split I am using the same structure as in nnUNet, which is documented here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/common_questions.md under \"Creating and managing splits.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Before doing this, I reorganized my files from structure\n",
    "\n",
    "-- data\n",
    "    -- d_train\n",
    "        -- images_normalized\n",
    "            HNC01_000_0000.nii.gz\n",
    "            HNC01_000_0001.nii.gz\n",
    "            HNC01_001_0000.nii.gz\n",
    "            HNC01_001_0001.nii.gz\n",
    "            ...\n",
    "        -- rois\n",
    "            HNC01_000_0001_roi.nii.gz\n",
    "            HNC01_001_0001_roi.nii.gz\n",
    "            ...\n",
    "        -- labels\n",
    "            HNC01_000.nii.gz\n",
    "            HNC01_001.nii.gz\n",
    "            ...\n",
    "\n",
    "To the structure\n",
    "-- data_as_deepmedic\n",
    "    -- d_train\n",
    "        -- HNC01_000\n",
    "            HNC01_000_0000.nii.gz\n",
    "            HNC01_000_0001.nii.gz\n",
    "            HNC01_000_0001_roi.nii.gz\n",
    "            HNC01_001.nii.gz\n",
    "        -- HNC01_001\n",
    "            ...\n",
    "        ...\n",
    "To match how DeepMedic organizes files. \n",
    "I am not including this script, since it depends on how your data is originally organized.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_train_dat_path = '/media/bizon/data2tb/deep_medic/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifti_as_deepmedic/train_normalized'\n",
    "splits_file_path = '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_preprocessed/Task500_HNC01/splits_final.pkl'\n",
    "config_path_train = '/media/bizon/data2tb/deep_medic/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/config_files/train'\n",
    "config_path_valid = '/media/bizon/data2tb/deep_medic/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/config_files/train/validation'\n",
    "\n",
    "#docker_train_dat_path = pathlib.Path(dm_train_dat_path)\n",
    "#docker_train_dat_path = pathlib.Path(*docker_train_dat_path.parts[4:])\n",
    "#docker_train_dat_path = str(f'/{docker_train_dat_path}')\n",
    "\n",
    "splits = load_pickle(splits_file_path)\n",
    "\n",
    "def generate_config_files(train_or_valid, destination_path):\n",
    "    for fold in np.arange(len(splits)):\n",
    "        files_ct = []\n",
    "        files_pt = []\n",
    "        files_roi = []\n",
    "        files_label = []\n",
    "        if train_or_valid == 'train':\n",
    "            dat = splits[fold]['train']\n",
    "        elif train_or_valid == 'val':\n",
    "            dat = splits[fold]['val']\n",
    "\n",
    "        absolute_subtring = '/media/bizon/data2tb/deep_medic/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/'\n",
    "        relative_substring = '../../'\n",
    "        \n",
    "        for f in dat:\n",
    "            fname_ct = join(dm_train_dat_path,f,f'{f}_0000.nii.gz')\n",
    "            fname_pet = join(dm_train_dat_path,f,f'{f}_0001.nii.gz')\n",
    "            fname_roi = join(dm_train_dat_path,f,f'{f}_0001_roi.nii.gz')\n",
    "            fname_label = join(dm_train_dat_path,f,f'{f}.nii.gz')\n",
    "            #ct\n",
    "            if isfile(fname_ct):\n",
    "                files_ct.append(fname_ct.replace(absolute_subtring,relative_substring))\n",
    "            else: \n",
    "                print('ERROR: CT file did not exist')\n",
    "            #pet\n",
    "            if isfile(fname_pet):\n",
    "                files_pt.append(fname_pet.replace(absolute_subtring,relative_substring))\n",
    "            else: \n",
    "                print('ERROR: PET file did not exist')\n",
    "            #roi\n",
    "            if isfile(fname_roi):\n",
    "                files_roi.append(fname_roi.replace(absolute_subtring,relative_substring))\n",
    "            else: \n",
    "                print('ERROR: ROI file did not exist')\n",
    "            #label\n",
    "            if isfile(fname_label):\n",
    "                files_label.append(fname_label.replace(absolute_subtring,relative_substring))\n",
    "            else: \n",
    "                print('ERROR: Label file did not exist')\n",
    "        #print(files_fold0_ct)\n",
    "        all_im_roi_labs = [files_ct, files_pt, files_roi, files_label]\n",
    "        out_files = ['ct', 'pet', 'roi', 'labels']\n",
    "        for i, modality in enumerate(out_files):\n",
    "            outF = open(join(destination_path,f'{modality}_fold{fold}.cfg'), 'w')\n",
    "            for line in all_im_roi_labs[i]:\n",
    "            # write line to output file\n",
    "                outF.write(line)\n",
    "                outF.write(\"\\n\")\n",
    "            outF.close()\n",
    "\n",
    "generate_config_files(train_or_valid = 'train', destination_path = config_path_train)\n",
    "generate_config_files(train_or_valid = 'val', destination_path = config_path_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casting the data to float32 and int16\n",
    "Running DeepMedic it turned out a large part of the training time was spent on loading the data.\n",
    "This is due to saving everything as float64. \n",
    "To improve efficiency and training time, I concvert images to float32 and label files to int16. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This bit is the same as file MEDIcaTe/deepMedic/conv.py which is used to run process in background (and go home to get some sleep :) )\n",
    "Had to rerun this because I did something wrong at first attempt so I converted to multiprocess to avoid the wait.\n",
    "\n",
    "Note: ensure to create destination path 'path_to_data_dst' before running\n",
    "'''\n",
    "from multiprocessing import Pool\n",
    "path_to_data_src = '/media/bizon/data2tb/deep_medic/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifti_as_deepmedic/train'\n",
    "path_to_data_dst = '/media/bizon/data2tb/deep_medic/homes/kovacs/project_data/hnc-auto-contouring/deepMedic/data_nifti_as_deepmedic/train_r'\n",
    "\n",
    "def process_image(name):\n",
    "    cur_src_path = join(path_to_data_src,name)\n",
    "    cur_dst_path = join(path_to_data_dst,name)\n",
    "    if not isdir(cur_dst_path):\n",
    "        os.mkdir(cur_dst_path)\n",
    "    for fi in listdir(cur_src_path):\n",
    "        cur_src_file_path = join(cur_src_path,fi)\n",
    "        cur_dst_file_path = join(cur_dst_path,fi)\n",
    "        if not isfile(cur_dst_file_path):\n",
    "            if (fi[-11:-7] == '0000') or (fi[-11:-7] == '0001'):\n",
    "                convert_nii_to_float32(cur_src_file_path,cur_dst_file_path)\n",
    "                print(f'Converted {fi} to float32')\n",
    "            else: \n",
    "                convert_nii_to_int16(cur_src_file_path,cur_dst_file_path)\n",
    "                print(f'Converted {fi} to int16')\n",
    "\n",
    "pool = Pool()\n",
    "pool.map(process_image, listdir(path_to_data_src))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f15886cd8b12a18a8b1aad558daa784c79bb1174f3258c3f4517d856494c4dc3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('nn_unet_cnl1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}



Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

lowres_segmentations is None. Attempting to predict 3d_lowres first...
This model expects 2 input modalities for each image
Found 1 unique case ids, here are some examples: ['HNC02_000']
If they don't look right, make sure to double check your filenames. They must end with _0000.nii.gz etc
number of cases: 1
number of cases that still need to be predicted: 0
emptying cuda cache
loading parameters for folds, None
folds is None so we will automatically look for output folders (not using 'all'!)
found the following folds:  ['/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4']
using the following model files:  ['/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_final_checkpoint.model', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1/model_final_checkpoint.model', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2/model_final_checkpoint.model', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3/model_final_checkpoint.model', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_lowres/Task500_HNC01/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4/model_final_checkpoint.model']
starting preprocessing generator
starting prediction...
inference done. Now waiting for the segmentation export to finish...
postprocessing...
3d_lowres done
using model stored in  /homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_cascade_fullres/Task500_HNC01/nnUNetTrainerV2CascadeFullRes__nnUNetPlansv2.1
This model expects 2 input modalities for each image
Found 1 unique case ids, here are some examples: ['HNC02_000']
If they don't look right, make sure to double check your filenames. They must end with _0000.nii.gz etc
number of cases: 1
number of cases that still need to be predicted: 1
emptying cuda cache
loading parameters for folds, None
folds is None so we will automatically look for output folders (not using 'all'!)
found the following folds:  ['/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_cascade_fullres/Task500_HNC01/nnUNetTrainerV2CascadeFullRes__nnUNetPlansv2.1/fold_0', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_cascade_fullres/Task500_HNC01/nnUNetTrainerV2CascadeFullRes__nnUNetPlansv2.1/fold_1', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_cascade_fullres/Task500_HNC01/nnUNetTrainerV2CascadeFullRes__nnUNetPlansv2.1/fold_2', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_cascade_fullres/Task500_HNC01/nnUNetTrainerV2CascadeFullRes__nnUNetPlansv2.1/fold_3', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_cascade_fullres/Task500_HNC01/nnUNetTrainerV2CascadeFullRes__nnUNetPlansv2.1/fold_4']
using the following model files:  ['/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_cascade_fullres/Task500_HNC01/nnUNetTrainerV2CascadeFullRes__nnUNetPlansv2.1/fold_0/model_final_checkpoint.model', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_cascade_fullres/Task500_HNC01/nnUNetTrainerV2CascadeFullRes__nnUNetPlansv2.1/fold_1/model_final_checkpoint.model', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_cascade_fullres/Task500_HNC01/nnUNetTrainerV2CascadeFullRes__nnUNetPlansv2.1/fold_2/model_final_checkpoint.model', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_cascade_fullres/Task500_HNC01/nnUNetTrainerV2CascadeFullRes__nnUNetPlansv2.1/fold_3/model_final_checkpoint.model', '/homes/kovacs/project_data/hnc-auto-contouring/nnUNet/nnUNet_trained_models/nnUNet/3d_cascade_fullres/Task500_HNC01/nnUNetTrainerV2CascadeFullRes__nnUNetPlansv2.1/fold_4/model_final_checkpoint.model']
starting preprocessing generator
starting prediction...
preprocessing /homes/kovacs/project_data/hnc-auto-contouring/hnc_rigs_all/data_nifty/t_r196/predictions/nnunet/labels_nn_unet_m2/HNC02_000.nii.gz
using preprocessor GenericPreprocessor
before crop: (2, 175, 512, 512) after crop: (2, 175, 512, 512) spacing: [2.        0.9765625 0.9765625] 

no resampling necessary
no resampling necessary
before: {'spacing': array([2.       , 0.9765625, 0.9765625]), 'spacing_transposed': array([2.       , 0.9765625, 0.9765625]), 'data.shape (data is transposed)': (2, 175, 512, 512)} 
after:  {'spacing': array([2.       , 0.9765625, 0.9765625]), 'data.shape (data is resampled)': (2, 175, 512, 512)} 

(3, 175, 512, 512)
This worker has ended successfully, no errors to report
force_separate_z: None interpolation order: 1
no resampling necessary
predicting /homes/kovacs/project_data/hnc-auto-contouring/hnc_rigs_all/data_nifty/t_r196/predictions/nnunet/labels_nn_unet_m2/HNC02_000.nii.gz
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (3, 175, 512, 512)
patch size: [ 64 192 160]
steps (x, y, and z): [[0, 28, 56, 83, 111], [0, 80, 160, 240, 320], [0, 70, 141, 211, 282, 352]]
number of tiles: 150
computing Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (3, 175, 512, 512)
patch size: [ 64 192 160]
steps (x, y, and z): [[0, 28, 56, 83, 111], [0, 80, 160, 240, 320], [0, 70, 141, 211, 282, 352]]
number of tiles: 150
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (3, 175, 512, 512)
patch size: [ 64 192 160]
steps (x, y, and z): [[0, 28, 56, 83, 111], [0, 80, 160, 240, 320], [0, 70, 141, 211, 282, 352]]
number of tiles: 150
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (3, 175, 512, 512)
patch size: [ 64 192 160]
steps (x, y, and z): [[0, 28, 56, 83, 111], [0, 80, 160, 240, 320], [0, 70, 141, 211, 282, 352]]
number of tiles: 150
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (3, 175, 512, 512)
patch size: [ 64 192 160]
steps (x, y, and z): [[0, 28, 56, 83, 111], [0, 80, 160, 240, 320], [0, 70, 141, 211, 282, 352]]
number of tiles: 150
using precomputed Gaussian
prediction done
inference done. Now waiting for the segmentation export to finish...
postprocessing...

real	4m45.937s
user	3m51.415s
sys	0m47.729s
